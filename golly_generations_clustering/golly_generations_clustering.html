<!DOCTYPE html>
<html>

<head>
  <meta charset=utf-8>
  <title>
    golly_generations_clustering
  </title>

  <!-- highlight.js -->
  <link rel="stylesheet" href="../script/highlight/idea.css">
  <script src="../script/highlight/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <!-- KaTeX -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y"
    crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx"
    crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe"
    crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>


  <style>
    body {
      max-width: 704px;
      margin: auto;
      padding: 32px 8px;
    }

    img {
      max-width: 100%;
    }

    video {
      max-width: 100%;
    }

    kbd {
      border-style: solid;
      border-width: 1px 2px 2px 1px;
      border-radius: 2px;
      padding: 2px;
      margin: 2px;
    }

    a {
      text-decoration: none;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
      color: #004444;
      border-left: solid 8px #eeeeee;
      padding-left: 8px;
    }

    code {
      color: #004444;
    }

    pre code {
      border: 4px solid #eeeeee;
    }

    li {
      margin: 8px;
    }

    footer {
      border-top: 1px gray solid;
      padding: 0.5em;
      margin-top: 1em;
    }

    canvas {
      /* image-rendering: pixelated; */
      display: inline-block;
      border-style: solid;
      border-width: 1px;
      border-color: #627f84;
    }

    .controlBlock {
      display: inline-block;
      width: 450px;
      text-align: left;
      vertical-align: top;
      margin-left: 4px;
    }

    input[type="button"] {
      background-color: #ffffff;
      border: 2px solid #aaaaaa;
      font-size: 16px;
      height: 32px;
    }

    input[type="button"]:hover {
      background-color: #ffffff;
      border: 2px solid #aaccff;
    }

    div.numberInput {
      display: block;
      white-space: nowrap;
    }

    div.numberInput:hover {
      background-color: #e0ecff;
    }

    .numberInputLabel {
      /* max 12 letter  */
      display: inline-block;
      margin: 0 8px 0 8px;
      text-align: left;
      vertical-align: middle;
      width: 100px;

      font-size: 10pt;
      font-family: 'Courier New', Courier, monospace;
    }

    .numberInputNumber {
      display: inline-block;
      vertical-align: middle;
      width: 120px;
    }

    .numberInputRange {
      display: inline-block;
      vertical-align: middle;
      width: 160px;
    }

    .pullDownMenu {
      display: inline-block;
      text-align: center;
    }

    .pullDownMenu:hover {
      background-color: #e0ecff;
    }

    select {
      background-color: #ffffff;
      border: 2px solid #aaaaaa;
      height: 24px;
      vertical-align: middle;
      font-size: 12px;
    }

    select:hover {
      background-color: #ffffff;
      border: 2px solid #aaccff;
    }
  </style>
</head>

<body>
  <h1 id="golly-の-generations-で作った音のクラスタリング">Golly の Generations で作った音のクラスタリング</h1>
<p><a href="http://golly.sourceforge.net/">Golly</a> の <a href="http://golly.sourceforge.net/Help/Algorithms/Generations.html">Genrations</a> という<a href="https://ja.wikipedia.org/wiki/%E3%82%BB%E3%83%AB%E3%83%BB%E3%82%AA%E3%83%BC%E3%83%88%E3%83%9E%E3%83%88%E3%83%B3">セルオートマトン</a>のルールを使って音を作りました。</p>
<iframe width="640" height="360" src="https://www.youtube.com/embed/zlPi7BwqFwo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>似たような音に分類したくなったので、音から得られた<a href="http://www.practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/">MFCC</a>を特徴ベクトルとして<a href="https://en.wikipedia.org/wiki/K-means_clustering">K-Means</a>でクラスタリングしました。</p>
<h2 id="データセット">データセット</h2>
<p>Golly の generations から生成した音のデータセットを次のリンクからダウンロードできます。</p>
<ul>
<li><a href="https://drive.google.com/file/d/1wbyGz6bbGULksH3vOchL7za1bPzNSNHs/view?usp=sharing">Golly generations data set (76MB)</a></li>
</ul>
<p><a href="https://www.7-zip.org/">7zip</a>で解凍できます。</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb1-1" data-line-number="1">$ <span class="ex">7z</span> x golly_generations_cluster.7z</a></code></pre></div>
<p>解凍してできる <code>cluster</code> 内の <code>generations</code> がデータセットです。その他のディレクトリはクラスタリングの結果です。</p>
<h2 id="プロトタイプ">プロトタイプ</h2>
<p>手始めに次のようなコードを書きました。</p>
<p><code>scipy.signal.spectrogram</code> から得たスペクトログラムを <code>numpy.ravel</code> で1次元にして <code>sklearn.cluster.KMeans</code> でクラスタリングしています。</p>
<p>計算に時間がかかるので <code>numpy.save</code> で計算結果を保存しています。</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="im">import</span> numpy</a>
<a class="sourceLine" id="cb2-2" data-line-number="2"><span class="im">import</span> scipy.signal</a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="im">import</span> sklearn.cluster</a>
<a class="sourceLine" id="cb2-4" data-line-number="4"><span class="im">import</span> shutil</a>
<a class="sourceLine" id="cb2-5" data-line-number="5"><span class="im">import</span> soundfile</a>
<a class="sourceLine" id="cb2-6" data-line-number="6"><span class="im">from</span> pathlib <span class="im">import</span> Path</a>
<a class="sourceLine" id="cb2-7" data-line-number="7"></a>
<a class="sourceLine" id="cb2-8" data-line-number="8"><span class="kw">def</span> extract_feature(path, n_frame<span class="op">=</span><span class="dv">39</span>):</a>
<a class="sourceLine" id="cb2-9" data-line-number="9">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb2-10" data-line-number="10"><span class="co">    スペクトログラムは2次元のデータ。</span></a>
<a class="sourceLine" id="cb2-11" data-line-number="11"><span class="co">    sklearn.cluster で使えるように numpy.ravel で1次元にして返す。</span></a>
<a class="sourceLine" id="cb2-12" data-line-number="12"></a>
<a class="sourceLine" id="cb2-13" data-line-number="13"><span class="co">    spectrogram.shape = (n_freq, n_frame)</span></a>
<a class="sourceLine" id="cb2-14" data-line-number="14"></a>
<a class="sourceLine" id="cb2-15" data-line-number="15"><span class="co">    n_frame のデフォルト値はテストに使ったデータセットを調べて決めた。</span></a>
<a class="sourceLine" id="cb2-16" data-line-number="16"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb2-17" data-line-number="17">    data, samplerate <span class="op">=</span> soundfile.read(<span class="bu">str</span>(path))</a>
<a class="sourceLine" id="cb2-18" data-line-number="18">    frequency, time, spectrogram <span class="op">=</span> scipy.signal.spectrogram(data, samplerate)</a>
<a class="sourceLine" id="cb2-19" data-line-number="19"></a>
<a class="sourceLine" id="cb2-20" data-line-number="20">    <span class="cf">if</span> spectrogram.shape[<span class="dv">1</span>] <span class="op">&lt;</span> n_frame:</a>
<a class="sourceLine" id="cb2-21" data-line-number="21">        zeros <span class="op">=</span> numpy.zeros((spectrogram.shape[<span class="dv">0</span>],</a>
<a class="sourceLine" id="cb2-22" data-line-number="22">                             n_frame <span class="op">-</span> spectrogram.shape[<span class="dv">1</span>]))</a>
<a class="sourceLine" id="cb2-23" data-line-number="23">        spectrogram <span class="op">=</span> numpy.concatenate((spectrogram, zeros), axis<span class="op">=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb2-24" data-line-number="24">    <span class="cf">elif</span> spectrogram.shape[<span class="dv">1</span>] <span class="op">&gt;</span> n_frame:</a>
<a class="sourceLine" id="cb2-25" data-line-number="25">        spectrogram <span class="op">=</span> spectrogram[:][<span class="dv">0</span>:n_frame]</a>
<a class="sourceLine" id="cb2-26" data-line-number="26"></a>
<a class="sourceLine" id="cb2-27" data-line-number="27">    <span class="cf">return</span> numpy.ravel(numpy.transpose(spectrogram))</a>
<a class="sourceLine" id="cb2-28" data-line-number="28"></a>
<a class="sourceLine" id="cb2-29" data-line-number="29"><span class="kw">def</span> write_result(output_directory, n_clusters, labels, filepath):</a>
<a class="sourceLine" id="cb2-30" data-line-number="30">    <span class="cf">if</span> output_directory.exists():</a>
<a class="sourceLine" id="cb2-31" data-line-number="31">        shutil.rmtree(output_directory)</a>
<a class="sourceLine" id="cb2-32" data-line-number="32"></a>
<a class="sourceLine" id="cb2-33" data-line-number="33">    digits <span class="op">=</span> <span class="bu">len</span>(<span class="bu">str</span>(<span class="bu">abs</span>(n_clusters <span class="op">-</span> <span class="dv">1</span>)))</a>
<a class="sourceLine" id="cb2-34" data-line-number="34">    output_directories <span class="op">=</span> [</a>
<a class="sourceLine" id="cb2-35" data-line-number="35">        output_directory <span class="op">/</span> Path(<span class="ss">f&quot;</span><span class="sc">{</span>index<span class="sc">:</span><span class="dv">0</span>{digits}<span class="sc">d}</span><span class="ss">&quot;</span>)</a>
<a class="sourceLine" id="cb2-36" data-line-number="36">        <span class="cf">for</span> index <span class="kw">in</span> <span class="bu">range</span>(n_clusters)</a>
<a class="sourceLine" id="cb2-37" data-line-number="37">    ]</a>
<a class="sourceLine" id="cb2-38" data-line-number="38"></a>
<a class="sourceLine" id="cb2-39" data-line-number="39">    <span class="cf">for</span> directory <span class="kw">in</span> output_directories:</a>
<a class="sourceLine" id="cb2-40" data-line-number="40">        directory.mkdir(parents<span class="op">=</span><span class="va">True</span>, exist_ok<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb2-41" data-line-number="41"></a>
<a class="sourceLine" id="cb2-42" data-line-number="42">    <span class="cf">for</span> label, path <span class="kw">in</span> <span class="bu">zip</span>(labels, filepath):</a>
<a class="sourceLine" id="cb2-43" data-line-number="43">        shutil.copy(path, output_directories[label])</a>
<a class="sourceLine" id="cb2-44" data-line-number="44"></a>
<a class="sourceLine" id="cb2-45" data-line-number="45"><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</a>
<a class="sourceLine" id="cb2-46" data-line-number="46">    directory_path <span class="op">=</span> Path(<span class="st">&quot;generations&quot;</span>)</a>
<a class="sourceLine" id="cb2-47" data-line-number="47">    <span class="cf">if</span> <span class="kw">not</span> directory_path.is_dir():</a>
<a class="sourceLine" id="cb2-48" data-line-number="48">        <span class="bu">print</span>(<span class="st">&quot;Invalid path.&quot;</span>)</a>
<a class="sourceLine" id="cb2-49" data-line-number="49"></a>
<a class="sourceLine" id="cb2-50" data-line-number="50">    filepath <span class="op">=</span> [path <span class="cf">for</span> path <span class="kw">in</span> directory_path.glob(<span class="st">&quot;*.wav&quot;</span>)]</a>
<a class="sourceLine" id="cb2-51" data-line-number="51">    features <span class="op">=</span> numpy.array([extract_feature(path) <span class="cf">for</span> path <span class="kw">in</span> filepath])</a>
<a class="sourceLine" id="cb2-52" data-line-number="52"></a>
<a class="sourceLine" id="cb2-53" data-line-number="53">    n_clusters <span class="op">=</span> <span class="dv">40</span></a>
<a class="sourceLine" id="cb2-54" data-line-number="54">    cluster <span class="op">=</span> sklearn.cluster.KMeans(n_clusters<span class="op">=</span>n_clusters).fit(features)</a>
<a class="sourceLine" id="cb2-55" data-line-number="55"></a>
<a class="sourceLine" id="cb2-56" data-line-number="56">    write_result(</a>
<a class="sourceLine" id="cb2-57" data-line-number="57">        Path(<span class="st">&quot;cluster_spectrogram&quot;</span>), n_clusters, cluster.labels_, filepath)</a>
<a class="sourceLine" id="cb2-58" data-line-number="58"></a>
<a class="sourceLine" id="cb2-59" data-line-number="59">    numpy.save(<span class="st">&quot;data/filepath.npy&quot;</span>, filepath)</a>
<a class="sourceLine" id="cb2-60" data-line-number="60">    numpy.save(<span class="st">&quot;data/features.npy&quot;</span>, features)</a>
<a class="sourceLine" id="cb2-61" data-line-number="61">    numpy.save(<span class="st">&quot;data/features_shape.npy&quot;</span>, (<span class="dv">39</span>, <span class="dv">129</span>))</a>
<a class="sourceLine" id="cb2-62" data-line-number="62">    numpy.save(<span class="st">&quot;data/labels.npy&quot;</span>, cluster.labels_)</a>
<a class="sourceLine" id="cb2-63" data-line-number="63">    numpy.save(<span class="st">&quot;data/centers.npy&quot;</span>, cluster.cluster_centers_)</a></code></pre></div>
<ul>
<li><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.spectrogram.html">scipy.signal.spectrogram — SciPy v1.1.0 Reference Guide</a></li>
<li><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ravel.html">numpy.ravel — NumPy v1.15 Manual</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html">sklearn.cluster.KMeans — scikit-learn 0.20.1 documentation</a></li>
</ul>
<h2 id="クラスタリング手法の選定">クラスタリング手法の選定</h2>
<p>耳で聞いた印象がいまいちだったので <a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.cluster"><code>sklearn.cluster</code></a> の中から次のクラスタリング手法を試しました。</p>
<ul>
<li><code>KMeans</code></li>
<li><code>AffinityPropagation</code></li>
<li><code>AgglomerativeClustering</code></li>
<li><code>SpectralClustering</code></li>
<li><code>DBSCAN</code></li>
</ul>
<p><code>Agglomerative</code> と <code>KMeans</code> は似たような結果が出ました。</p>
<p><code>AffinityPropagation</code> はアルゴリズム側でクラスタの数を自動的に決めてくれます。 <code>damping</code> をデフォルトの0.5にするとクラスタの数が多くなりすぎたので、適当に0.6としたところ119のサンプルに対して60ほどあったクラスタが15まで減りました。</p>
<p><code>SpectralClustering</code> の結果は良くなかったです。</p>
<p><code>DBSCAN</code> はサンプルの数と同じだけのクラスタができる結果となりました。<a href="https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/">Visualizing DBSCAN Clustering</a> を見ると空間を格子に区切って、格子内のデータポイントの数に応じてクラスタを作っています。今回のデータでは次元の高さに対してデータポイントの数が少なすぎるためにクラスタが形成されにくいのかもしれません。</p>
<p>ここでは Golly の generations で作った音のクラスタリングには <code>KMeans</code> で十分と判断しました。</p>
<p>クラスタリング手法では結果が改善しないこともわかったので特徴抽出を変えることにしました。</p>
<h2 id="mfcc">MFCC</h2>
<p><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.spectrogram.html"><code>numpy.spectrogram</code></a> を使ったクラスタリングの結果に満足できなかったので <a href="https://python-speech-features.readthedocs.io/en/latest/"><code>python_speech_features</code></a> をインストールして <a href="http://www.practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/">MFCC</a> を使うことにしました。</p>
<p>プロトタイプの <code>extract_feature</code> を次のように変更しました。</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="im">import</span> python_speech_features</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"></a>
<a class="sourceLine" id="cb3-3" data-line-number="3"><span class="kw">def</span> extract_feature(path, n_frame<span class="op">=</span><span class="dv">19</span>):</a>
<a class="sourceLine" id="cb3-4" data-line-number="4">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb3-5" data-line-number="5"><span class="co">    mfcc.shape = (n_frame, n_cepstrum)</span></a>
<a class="sourceLine" id="cb3-6" data-line-number="6"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb3-7" data-line-number="7">    data, samplerate <span class="op">=</span> soundfile.read(<span class="bu">str</span>(path))</a>
<a class="sourceLine" id="cb3-8" data-line-number="8">    nfft <span class="op">=</span> <span class="dv">1024</span></a>
<a class="sourceLine" id="cb3-9" data-line-number="9">    mfcc <span class="op">=</span> python_speech_features.mfcc(</a>
<a class="sourceLine" id="cb3-10" data-line-number="10">        data,</a>
<a class="sourceLine" id="cb3-11" data-line-number="11">        samplerate,</a>
<a class="sourceLine" id="cb3-12" data-line-number="12">        winlen<span class="op">=</span>nfft <span class="op">/</span> samplerate,</a>
<a class="sourceLine" id="cb3-13" data-line-number="13">        winstep<span class="op">=</span><span class="fl">0.01</span>,</a>
<a class="sourceLine" id="cb3-14" data-line-number="14">        numcep<span class="op">=</span><span class="dv">26</span>,</a>
<a class="sourceLine" id="cb3-15" data-line-number="15">        nfilt<span class="op">=</span><span class="dv">52</span>,</a>
<a class="sourceLine" id="cb3-16" data-line-number="16">        nfft<span class="op">=</span>nfft,</a>
<a class="sourceLine" id="cb3-17" data-line-number="17">        preemph<span class="op">=</span><span class="fl">0.97</span>,</a>
<a class="sourceLine" id="cb3-18" data-line-number="18">        ceplifter<span class="op">=</span><span class="dv">22</span>,</a>
<a class="sourceLine" id="cb3-19" data-line-number="19">    )</a>
<a class="sourceLine" id="cb3-20" data-line-number="20"></a>
<a class="sourceLine" id="cb3-21" data-line-number="21">    <span class="cf">if</span> mfcc.shape[<span class="dv">0</span>] <span class="op">&lt;</span> n_frame:</a>
<a class="sourceLine" id="cb3-22" data-line-number="22">        zeros <span class="op">=</span> numpy.zeros((n_frame <span class="op">-</span> mfcc.shape[<span class="dv">0</span>], mfcc.shape[<span class="dv">1</span>]))</a>
<a class="sourceLine" id="cb3-23" data-line-number="23">        mfcc <span class="op">=</span> numpy.concatenate((mfcc, zeros), axis<span class="op">=</span><span class="dv">0</span>)</a>
<a class="sourceLine" id="cb3-24" data-line-number="24">    <span class="cf">elif</span> mfcc.shape[<span class="dv">0</span>] <span class="op">&gt;</span> n_frame:</a>
<a class="sourceLine" id="cb3-25" data-line-number="25">        mfcc <span class="op">=</span> mfcc[<span class="dv">0</span>:n_frame]</a>
<a class="sourceLine" id="cb3-26" data-line-number="26"></a>
<a class="sourceLine" id="cb3-27" data-line-number="27">    <span class="cf">return</span> numpy.ravel(mfcc)</a></code></pre></div>
<p><code>winlen * samplerate &gt; nfft</code> のときにエラーが出るので <code>winlen</code> は <code>nfft</code> の値から決めています。</p>
<p><code>numcep</code> と <code>nfilt</code> は適当にデフォルトの2倍にしました。</p>
<p>Golly の generations で作った音は低周波成分がそれなりに含まれるので、ルールと音の関係を調べるなら <code>preemph</code> は0でいいかもしれません。ここでは耳での聞こえ方で分類したかったのでデフォルト値を使っています。</p>
<p>Golly の generations で作った音のクラスタリングについては、MFCCを使うことでスペクトログラムを使うよりも私の主観では良い結果が出ました。データポイントの次元が減るので計算も早くなります。</p>
<ul>
<li><a href="http://www.practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/">Practical Cryptography - Mel Frequency Cepstral Coefficient (MFCC) tutorial</a></li>
<li><a href="https://dsp.stackexchange.com/questions/45786/pre-emphasis-filter-for-speech-recognition">fir - Pre-emphasis filter for speech recognition - Signal Processing Stack Exchange</a></li>
<li><a href="https://www.quora.com/Why-is-pre-emphasis-i-e-passing-the-speech-signal-through-a-first-order-high-pass-filter-required-in-speech-processing-and-how-does-it-work">Why is pre-emphasis (i.e. passing the speech signal through a first order high pass filter) required in speech processing and how does it work? - Quora</a></li>
</ul>
<h2 id="elbow-method">Elbow Method</h2>
<p><code>KMeans</code> のパラメータ <code>n_clusters</code> を決めるために <a href="https://bl.ocks.org/rpgove/0060ff3b656618e9136b">elbow method</a> を試しました。</p>
<p><code>KMeans</code> の誤差はクラスタの数を増やすと小さくなります。また、クラスタの数が増えると誤差の減り方が緩やかになってきます。 Elbow method では誤差の減り方が十分に緩やかな範囲で最も小さいクラスタの数を使います。誤差の減り方が緩やかかどうかの判断はデータセットに応じて人間が適当に行うようです。</p>
<p>実装では <code>sklearn.cluster.KMeans.inertia_</code> がそのまま使えます。</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> pyplot</a>
<a class="sourceLine" id="cb4-2" data-line-number="2"><span class="im">import</span> numpy</a>
<a class="sourceLine" id="cb4-3" data-line-number="3"><span class="im">import</span> python_speech_features</a>
<a class="sourceLine" id="cb4-4" data-line-number="4"><span class="im">import</span> sklearn.cluster</a>
<a class="sourceLine" id="cb4-5" data-line-number="5"><span class="im">import</span> soundfile</a>
<a class="sourceLine" id="cb4-6" data-line-number="6"><span class="im">from</span> pathlib <span class="im">import</span> Path</a>
<a class="sourceLine" id="cb4-7" data-line-number="7"></a>
<a class="sourceLine" id="cb4-8" data-line-number="8"><span class="kw">def</span> get_inertia(n_clusters, features):</a>
<a class="sourceLine" id="cb4-9" data-line-number="9">    cluster <span class="op">=</span> sklearn.cluster.KMeans(n_clusters<span class="op">=</span>n_clusters).fit(features)</a>
<a class="sourceLine" id="cb4-10" data-line-number="10">    <span class="cf">return</span> cluster.inertia_</a>
<a class="sourceLine" id="cb4-11" data-line-number="11"></a>
<a class="sourceLine" id="cb4-12" data-line-number="12"><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</a>
<a class="sourceLine" id="cb4-13" data-line-number="13">    features <span class="op">=</span> numpy.load(<span class="st">&quot;features.npy&quot;</span>)</a>
<a class="sourceLine" id="cb4-14" data-line-number="14"></a>
<a class="sourceLine" id="cb4-15" data-line-number="15">    x_range <span class="op">=</span> (<span class="dv">2</span>, <span class="dv">101</span>)</a>
<a class="sourceLine" id="cb4-16" data-line-number="16">    errors <span class="op">=</span> [get_inertia(k, features) <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="op">*</span>x_range)]</a>
<a class="sourceLine" id="cb4-17" data-line-number="17">    k_value <span class="op">=</span> [k <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="op">*</span>x_range)]</a>
<a class="sourceLine" id="cb4-18" data-line-number="18"></a>
<a class="sourceLine" id="cb4-19" data-line-number="19">    pyplot.plot(k_value, errors, lw<span class="op">=</span><span class="dv">1</span>, color<span class="op">=</span><span class="st">&quot;gray&quot;</span>)</a>
<a class="sourceLine" id="cb4-20" data-line-number="20">    pyplot.plot(k_value, errors, <span class="st">&quot;o&quot;</span>, markersize<span class="op">=</span><span class="dv">3</span>, color<span class="op">=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb4-21" data-line-number="21">    pyplot.xlabel(<span class="st">&quot;n_clusters&quot;</span>)</a>
<a class="sourceLine" id="cb4-22" data-line-number="22">    pyplot.ylabel(<span class="st">&quot;error&quot;</span>)</a>
<a class="sourceLine" id="cb4-23" data-line-number="23">    pyplot.xlim((x_range[<span class="dv">0</span>], x_range[<span class="dv">1</span>] <span class="op">-</span> <span class="dv">1</span>))</a>
<a class="sourceLine" id="cb4-24" data-line-number="24">    pyplot.grid()</a>
<a class="sourceLine" id="cb4-25" data-line-number="25">    pyplot.show()</a></code></pre></div>
<p>出力されたプロットです。</p>
<figure>
<img src="img/mfcc/elbow_method.png" alt="Image of plot used for elbow method." style="width: 600px;padding-bottom: 12px;"/>
</figure>
<p>滑らかで elbow となる傾きが急に変わる箇所がないように見えます。今回は特に目的も正解もなくクラスタリングしているので <code>k=40</code> くらいでいい気がします。</p>
<ul>
<li><a href="https://bl.ocks.org/rpgove/0060ff3b656618e9136b">Using the elbow method to determine the optimal number of clusters for k-means clustering - bl.ocks.org</a></li>
<li><a href="https://www.quora.com/How-can-we-choose-a-good-K-for-K-means-clustering">How can we choose a ‘good’ K for K-means clustering? - Quora</a></li>
</ul>
<h2 id="t-sne-で視覚化">t-SNE で視覚化</h2>
<p>いい評価方法が思いつかないので、とりあえず <a href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding">t-SNE</a> で視覚化しました。</p>
<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html"><code>sklearn.manifold.TSNE</code></a> を使います。</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="im">import</span> numpy</a>
<a class="sourceLine" id="cb5-2" data-line-number="2"><span class="im">import</span> sklearn.manifold</a>
<a class="sourceLine" id="cb5-3" data-line-number="3"></a>
<a class="sourceLine" id="cb5-4" data-line-number="4">features <span class="op">=</span> numpy.load(<span class="st">&quot;data/features.npy&quot;</span>)</a>
<a class="sourceLine" id="cb5-5" data-line-number="5">tsne <span class="op">=</span> sklearn.manifold.TSNE(n_components<span class="op">=</span><span class="dv">2</span>).fit(features)</a>
<a class="sourceLine" id="cb5-6" data-line-number="6">numpy.save(<span class="st">&quot;data/embedding.npy&quot;</span>, tsne.embedding_)</a></code></pre></div>
<p>計算結果のプロットです。図の数字はデータポイントの属するクラスタの番号と対応しています。</p>
<figure>
<img src="img/mfcc/tsne.png" alt="Image of ." style="width: 600px;padding-bottom: 12px;"/>
</figure>
<h2 id="適当なプロット">適当なプロット</h2>
<p>クラスタの内容を調べるために適当に思いついたパラメータをプロットします。</p>
<p>中央値が表すMFCCです。各画像の縦が周波数で下から上に向かって大きくなります。横は時間で左から右に向かって進んでいます。明るい部分ほど係数が大きくなります。 <code>n</code> はクラスタに含まれるデータポイントの数を表しています。</p>
<figure>
<img src="img/mfcc/centers.png" alt="Image of plot of K-Means centers from mfcc features." style="width: 600px;padding-bottom: 12px;"/>
</figure>
<p>K-Meansの中央値と対応するデータポイントとの間での平均絶対誤差 (<a href="https://en.wikipedia.org/wiki/Mean_absolute_error">mean absolute error</a>) です。</p>
<figure>
<img src="img/mfcc/errors.png" alt="Image of plot of mean absolute errors between K-Means centers and corresponding data points." style="width: 600px;padding-bottom: 12px;"/>
</figure>
<p>以下は耳で聞いた印象です。</p>
<ul>
<li>0, 2, 15, 20, 25, 28 は低めのトーン。</li>
<li>1, 11, 21 はプチノイズ。</li>
<li>4, 7, 16 はカラーノイズ。</li>
<li>3, 8, 9, 12, 13, 14, 19, 29, 31, 35, 39 は高いトーン。</li>
<li>17, 18, 30, 34, 36 は高めのカラーノイズと高めのトーンの中間のような音。</li>
<li>22, 23, 24, 26, 37, 38 はプチノイズと高いトーン。</li>
<li>32, 33 は低めのカラーノイズと低めのトーンの中間のような音。</li>
</ul>
<p>特徴ベクトルを変えて出力したプロットを別ページにまとめました。</p>
<p><a href="gallery.html">プロットギャラリーを見る</a></p>
<h2 id="その他">その他</h2>
<p>ここではクラスタリングの結果について、ざっくり耳で聞いた判断しか行っていません。</p>
<p>MFCCを試した後でスペクトログラムを改善できないか試しました。</p>
<ul>
<li>データポイントの最小値、最大値の範囲を [0, 1] に正規化。</li>
<li>データポイントの最小値、最大値の範囲を [0, 1] に正規化してから <code>numpy.log</code> で対数に変換。</li>
</ul>
<p>どちらもMFCCと比べて良くなったとは感じませんでした。</p>
<p>Elbow method はヒューリスティックのわりに計算に時間がかかります。今回のような正解となるデータセットがない状態でのクラスタリングでは <code>KMeans</code> よりも、自動的にクラスタの数を決めてくれる <code>AffinityPropagation</code> を使ったほうが楽かもしれません。</p>


  <footer>
    <a href="../index.html">インデックスに戻る</a>
  </footer>
</body>

</html>

